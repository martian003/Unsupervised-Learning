{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9452fd5-4c35-4a5b-818a-90bb58aeff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ef2598f-8b3c-4e0a-b200-e8ec02213beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.array([\n",
    "    [0, 47, 14],  # C1\n",
    "    [50, 0, 0],   # C2\n",
    "    [0, 3, 36]    # C3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "551b94bc-bbb0-4c08-a15b-549ebf811538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_purity(confusion_matrix):\n",
    "   \n",
    "    total_samples = np.sum(confusion_matrix)\n",
    "    purity = np.sum(np.max(confusion_matrix, axis=1)) / total_samples\n",
    "    return purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4c48d67-6442-46a0-a125-cf6e03a09aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision(confusion_matrix):\n",
    "    num_classes = confusion_matrix.shape[1]\n",
    "    precision_list = []\n",
    "    \n",
    "    for j in range(num_classes):\n",
    "        TP = np.max(confusion_matrix[:, j])  \n",
    "        FP = np.sum(confusion_matrix[:, j]) - TP  \n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        precision_list.append(precision)\n",
    "    \n",
    "    return precision_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db7f9a3-e434-4689-9072-ca923d9680b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(confusion_matrix):\n",
    "    num_classes = confusion_matrix.shape[1]\n",
    "    recall_list = []\n",
    "    \n",
    "    for j in range(num_classes):\n",
    "        TP = np.max(confusion_matrix[:, j])\n",
    "        FN = np.sum(confusion_matrix[np.argmax(confusion_matrix[:, j]), :]) - TP  # False Negatives\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        recall_list.append(recall)\n",
    "    \n",
    "    return recall_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ecd3909-36f8-45a0-b55e-41a951e4aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f_measure(precision_list, recall_list):\n",
    "    f_measure_list = []\n",
    "    \n",
    "    for p, r in zip(precision_list, recall_list):\n",
    "        f_measure = 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
    "        f_measure_list.append(f_measure)\n",
    "    \n",
    "    return f_measure_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f06fd702-2d3e-466b-a417-b09f88fce4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "purity = compute_purity(confusion_matrix)\n",
    "precision_list = compute_precision(confusion_matrix)\n",
    "recall_list = compute_recall(confusion_matrix)\n",
    "f_measure_list = compute_f_measure(precision_list, recall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41720a48-9fd0-4f0a-8a53-bce52596c3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.8867\n",
      "Class T1 - Precision: 1.0000, Recall: 1.0000, F-Measure: 1.0000\n",
      "Class T2 - Precision: 0.9400, Recall: 0.7705, F-Measure: 0.8468\n",
      "Class T3 - Precision: 0.7200, Recall: 0.9231, F-Measure: 0.8090\n",
      "Macro-Averaged Precision: 0.8867\n",
      "Macro-Averaged Recall: 0.8979\n",
      "Macro-Averaged F-Measure: 0.8853\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(f\"Purity: {purity:.4f}\")\n",
    "\n",
    "for i, (p, r, f) in enumerate(zip(precision_list, recall_list, f_measure_list)):\n",
    "    print(f\"Class T{i+1} - Precision: {p:.4f}, Recall: {r:.4f}, F-Measure: {f:.4f}\")\n",
    "\n",
    "# Macro-Averaged Scores\n",
    "macro_precision = np.mean(precision_list)\n",
    "macro_recall = np.mean(recall_list)\n",
    "macro_f_measure = np.mean(f_measure_list)\n",
    "\n",
    "print(f\"Macro-Averaged Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro-Averaged Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro-Averaged F-Measure: {macro_f_measure:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b19bd-d577-41b6-a2df-4e626062e218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
